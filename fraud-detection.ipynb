{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset from the csv file using pandas\n",
    "data = pd.read_csv(\"creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7   \n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599  \\\n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25   \n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539  \\\n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a peek at the data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle Credit Card Fraud Dataset\n",
    "\n",
    "This dataset consists of transactions made by credit cards in September 2013 by European cardholders over a period of two days. The dataset is highly unbalanced with only 492 frauds out of 284,807 transactions, accounting for just 0.172% of all transactions.\n",
    "\n",
    "#### Features\n",
    "\n",
    "- **V1, V2, ..., V28**: These are the principal components obtained with Principal Component Analysis (PCA). Due to confidentiality issues, the original features from which these components were derived are not available. PCA is a method that transforms the original variables into a new set of variables which are linear combinations of the original variables and are orthogonal (independent) to each other. \n",
    "\n",
    "- **Time**: This feature represents the seconds elapsed between each transaction and the first transaction in the dataset. It allows tracking of the time context of each transaction.\n",
    "\n",
    "- **Amount**: This is the transaction amount for each record. This feature can be used for example-dependent cost-sensitive learning, meaning that the cost function can consider the transaction amount in fraud detection scenarios.\n",
    "\n",
    "- **Class**: This is the target variable that we aim to predict. It takes the value 1 in case of fraud and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0017304750013189597\n",
      "Fraud Cases: 492\n",
      "Valid Transactions: 284315\n"
     ]
    }
   ],
   "source": [
    "# Determine number of fraud cases in dataset\n",
    "fraud = data[data['Class'] == 1]\n",
    "valid = data[data['Class'] == 0]\n",
    "outlierFraction = len(fraud)/float(len(valid))\n",
    "print(outlierFraction)\n",
    "print('Fraud Cases: {}'.format(len(data[data['Class'] == 1])))\n",
    "print('Valid Transactions: {}'.format(len(data[data['Class'] == 0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Imbalanced Data in Fraud Detection\n",
    "\n",
    "Fraudulent transactions account for only 0.17% of total transactions, leading to a highly imbalanced dataset. In machine learning, an *imbalanced dataset* refers to a situation where the classes are not represented equally. \n",
    "\n",
    "For instance, consider a binary classification problem where 95% of the instances belong to Class A and only 5% of the instances belong to Class B. This dataset would be considered imbalanced.\n",
    "\n",
    "This imbalance can introduce a significant bias in our model training. Most machine learning algorithms are designed to maximize overall accuracy, which can be misleading when the classes are imbalanced. \n",
    "\n",
    "For example, in our case, a model could achieve a 99.83% accuracy rate by predicting every transaction to be non-fraudulent. However, such a model would be absolutely useless at detecting fraudulent transactions, which is our main objective. \n",
    "\n",
    "Therefore, we need to implement strategies to correct for the imbalance in our dataset.\n",
    "\n",
    "For now, lets see how the model performs without balancing, and then compare the results with a balanced set later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 30)\n",
      "(284807,)\n"
     ]
    }
   ],
   "source": [
    "# dividing the X and the Y from the dataset\n",
    "X = data.drop(['Class'], axis = 1)\n",
    "Y = data[\"Class\"]\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "# getting just the values for the sake of processing \n",
    "# (its a numpy array with no columns)\n",
    "xData = X.values\n",
    "yData = Y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data into training and testing set\n",
    "\n",
    "# Using Scikit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split the data into training and testing sets\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(\n",
    "        xData, yData, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing an ML Model for our usecase: Random Forest Classification\n",
    "The Random Forest algorithm is a powerful tool for detecting credit card fraud due to its inherent characteristics. It is an ensemble learning method that operates by constructing multiple decision trees and outputting the majority vote of individual trees. \n",
    "\n",
    "The model is less prone to overfitting due to the randomness and diversity among the individual trees. Moreover, the algorithm can handle a large amount of data with numerous variables and manage missing values, making it suitable for complex datasets such as credit card transactions. \n",
    "\n",
    "Its ability to estimate the importance of features can be beneficial in identifying significant indicators of fraud. Furthermore, the random forest algorithm works well with imbalanced datasets, which is often the case with fraud detection, where the number of legitimate transactions significantly outweighs fraudulent ones. Therefore, it's an effective technique for such tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the Random Forest Classifier (RANDOM FOREST)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# random forest model creation\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(xTrain, yTrain)\n",
    "# predictions\n",
    "yPred = rfc.predict(xTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model used is Random Forest classifier\n",
      "The accuracy is 0.9995786664794073\n",
      "The precision is 0.9743589743589743\n",
      "The recall is 0.7755102040816326\n",
      "The F1-Score is 0.8636363636363635\n",
      "The Matthews correlation coefficient is 0.8690748763736589\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the classifier\n",
    "# printing every score of the classifier\n",
    "# scoring in anything\n",
    "from sklearn.metrics import classification_report, accuracy_score \n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, matthews_corrcoef\n",
    "from sklearn.metrics import confusion_matrix\n",
    "  \n",
    "n_outliers = len(fraud)\n",
    "n_errors = (yPred != yTest).sum()\n",
    "print(\"The model used is Random Forest classifier\")\n",
    "  \n",
    "acc = accuracy_score(yTest, yPred)\n",
    "print(\"The accuracy is {}\".format(acc))\n",
    "  \n",
    "prec = precision_score(yTest, yPred)\n",
    "print(\"The precision is {}\".format(prec))\n",
    "  \n",
    "rec = recall_score(yTest, yPred)\n",
    "print(\"The recall is {}\".format(rec))\n",
    "  \n",
    "f1 = f1_score(yTest, yPred)\n",
    "print(\"The F1-Score is {}\".format(f1))\n",
    "  \n",
    "MCC = matthews_corrcoef(yTest, yPred)\n",
    "print(\"The Matthews correlation coefficient is {}\".format(MCC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Because of the massive dataset imbalance, we only want to focus on precision and recall. \n",
    "\n",
    "The model caught 77.55% of all the fraudulent transactions, so that means we have some room for improvement. But, for the transactions it labeled fraudulent, it was correct 97.435% of the time.\n",
    "\n",
    "I think we can improve this by cleaning up our dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
