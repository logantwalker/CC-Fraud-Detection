{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": [
                "# import the necessary packages\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from matplotlib import gridspec"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [],
            "source": [
                "# load the dataset from the csv file using pandas\n",
                "data = pd.read_csv(\"creditcard.csv\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>Time</th>\n",
                            "      <th>V1</th>\n",
                            "      <th>V2</th>\n",
                            "      <th>V3</th>\n",
                            "      <th>V4</th>\n",
                            "      <th>V5</th>\n",
                            "      <th>V6</th>\n",
                            "      <th>V7</th>\n",
                            "      <th>V8</th>\n",
                            "      <th>V9</th>\n",
                            "      <th>...</th>\n",
                            "      <th>V21</th>\n",
                            "      <th>V22</th>\n",
                            "      <th>V23</th>\n",
                            "      <th>V24</th>\n",
                            "      <th>V25</th>\n",
                            "      <th>V26</th>\n",
                            "      <th>V27</th>\n",
                            "      <th>V28</th>\n",
                            "      <th>Amount</th>\n",
                            "      <th>Class</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>0.0</td>\n",
                            "      <td>-1.359807</td>\n",
                            "      <td>-0.072781</td>\n",
                            "      <td>2.536347</td>\n",
                            "      <td>1.378155</td>\n",
                            "      <td>-0.338321</td>\n",
                            "      <td>0.462388</td>\n",
                            "      <td>0.239599</td>\n",
                            "      <td>0.098698</td>\n",
                            "      <td>0.363787</td>\n",
                            "      <td>...</td>\n",
                            "      <td>-0.018307</td>\n",
                            "      <td>0.277838</td>\n",
                            "      <td>-0.110474</td>\n",
                            "      <td>0.066928</td>\n",
                            "      <td>0.128539</td>\n",
                            "      <td>-0.189115</td>\n",
                            "      <td>0.133558</td>\n",
                            "      <td>-0.021053</td>\n",
                            "      <td>149.62</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>0.0</td>\n",
                            "      <td>1.191857</td>\n",
                            "      <td>0.266151</td>\n",
                            "      <td>0.166480</td>\n",
                            "      <td>0.448154</td>\n",
                            "      <td>0.060018</td>\n",
                            "      <td>-0.082361</td>\n",
                            "      <td>-0.078803</td>\n",
                            "      <td>0.085102</td>\n",
                            "      <td>-0.255425</td>\n",
                            "      <td>...</td>\n",
                            "      <td>-0.225775</td>\n",
                            "      <td>-0.638672</td>\n",
                            "      <td>0.101288</td>\n",
                            "      <td>-0.339846</td>\n",
                            "      <td>0.167170</td>\n",
                            "      <td>0.125895</td>\n",
                            "      <td>-0.008983</td>\n",
                            "      <td>0.014724</td>\n",
                            "      <td>2.69</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>1.0</td>\n",
                            "      <td>-1.358354</td>\n",
                            "      <td>-1.340163</td>\n",
                            "      <td>1.773209</td>\n",
                            "      <td>0.379780</td>\n",
                            "      <td>-0.503198</td>\n",
                            "      <td>1.800499</td>\n",
                            "      <td>0.791461</td>\n",
                            "      <td>0.247676</td>\n",
                            "      <td>-1.514654</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.247998</td>\n",
                            "      <td>0.771679</td>\n",
                            "      <td>0.909412</td>\n",
                            "      <td>-0.689281</td>\n",
                            "      <td>-0.327642</td>\n",
                            "      <td>-0.139097</td>\n",
                            "      <td>-0.055353</td>\n",
                            "      <td>-0.059752</td>\n",
                            "      <td>378.66</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>1.0</td>\n",
                            "      <td>-0.966272</td>\n",
                            "      <td>-0.185226</td>\n",
                            "      <td>1.792993</td>\n",
                            "      <td>-0.863291</td>\n",
                            "      <td>-0.010309</td>\n",
                            "      <td>1.247203</td>\n",
                            "      <td>0.237609</td>\n",
                            "      <td>0.377436</td>\n",
                            "      <td>-1.387024</td>\n",
                            "      <td>...</td>\n",
                            "      <td>-0.108300</td>\n",
                            "      <td>0.005274</td>\n",
                            "      <td>-0.190321</td>\n",
                            "      <td>-1.175575</td>\n",
                            "      <td>0.647376</td>\n",
                            "      <td>-0.221929</td>\n",
                            "      <td>0.062723</td>\n",
                            "      <td>0.061458</td>\n",
                            "      <td>123.50</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>2.0</td>\n",
                            "      <td>-1.158233</td>\n",
                            "      <td>0.877737</td>\n",
                            "      <td>1.548718</td>\n",
                            "      <td>0.403034</td>\n",
                            "      <td>-0.407193</td>\n",
                            "      <td>0.095921</td>\n",
                            "      <td>0.592941</td>\n",
                            "      <td>-0.270533</td>\n",
                            "      <td>0.817739</td>\n",
                            "      <td>...</td>\n",
                            "      <td>-0.009431</td>\n",
                            "      <td>0.798278</td>\n",
                            "      <td>-0.137458</td>\n",
                            "      <td>0.141267</td>\n",
                            "      <td>-0.206010</td>\n",
                            "      <td>0.502292</td>\n",
                            "      <td>0.219422</td>\n",
                            "      <td>0.215153</td>\n",
                            "      <td>69.99</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>5 rows Ã— 31 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "   Time        V1        V2        V3        V4        V5        V6        V7   \n",
                            "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599  \\\n",
                            "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
                            "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
                            "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
                            "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
                            "\n",
                            "         V8        V9  ...       V21       V22       V23       V24       V25   \n",
                            "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539  \\\n",
                            "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
                            "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
                            "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
                            "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
                            "\n",
                            "        V26       V27       V28  Amount  Class  \n",
                            "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
                            "1  0.125895 -0.008983  0.014724    2.69      0  \n",
                            "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
                            "3 -0.221929  0.062723  0.061458  123.50      0  \n",
                            "4  0.502292  0.219422  0.215153   69.99      0  \n",
                            "\n",
                            "[5 rows x 31 columns]"
                        ]
                    },
                    "execution_count": 17,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# take a peek at the data\n",
                "data.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Kaggle Credit Card Fraud Dataset\n",
                "\n",
                "This dataset consists of transactions made by credit cards in September 2013 by European cardholders over a period of two days. The dataset is highly unbalanced with only 492 frauds out of 284,807 transactions, accounting for just 0.172% of all transactions.\n",
                "\n",
                "#### Features\n",
                "\n",
                "- **V1, V2, ..., V28**: These are the principal components obtained with Principal Component Analysis (PCA). Due to confidentiality issues, the original features from which these components were derived are not available. PCA is a method that transforms the original variables into a new set of variables which are linear combinations of the original variables and are orthogonal (independent) to each other. \n",
                "\n",
                "- **Time**: This feature represents the seconds elapsed between each transaction and the first transaction in the dataset. It allows tracking of the time context of each transaction.\n",
                "\n",
                "- **Amount**: This is the transaction amount for each record. This feature can be used for example-dependent cost-sensitive learning, meaning that the cost function can consider the transaction amount in fraud detection scenarios.\n",
                "\n",
                "- **Class**: This is the target variable that we aim to predict. It takes the value 1 in case of fraud and 0 otherwise."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "0.0017304750013189597\n",
                        "Fraud Cases: 492\n",
                        "Valid Transactions: 284315\n"
                    ]
                }
            ],
            "source": [
                "# Determine number of fraud cases in dataset\n",
                "fraud = data[data['Class'] == 1]\n",
                "valid = data[data['Class'] == 0]\n",
                "outlierFraction = len(fraud)/float(len(valid))\n",
                "print(outlierFraction)\n",
                "print('Fraud Cases: {}'.format(len(data[data['Class'] == 1])))\n",
                "print('Valid Transactions: {}'.format(len(data[data['Class'] == 0])))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Dealing with Imbalanced Data in Fraud Detection\n",
                "\n",
                "Fraudulent transactions account for only 0.17% of total transactions, leading to a highly imbalanced dataset. In machine learning, an *imbalanced dataset* refers to a situation where the classes are not represented equally. \n",
                "\n",
                "For instance, consider a binary classification problem where 95% of the instances belong to Class A and only 5% of the instances belong to Class B. This dataset would be considered imbalanced.\n",
                "\n",
                "This imbalance can introduce a significant bias in our model training. Most machine learning algorithms are designed to maximize overall accuracy, which can be misleading when the classes are imbalanced. \n",
                "\n",
                "For example, in our case, a model could achieve a 99.83% accuracy rate by predicting every transaction to be non-fraudulent. However, such a model would be absolutely useless at detecting fraudulent transactions, which is our main objective. \n",
                "\n",
                "Therefore, we need to implement strategies to correct for the imbalance in our dataset.\n",
                "\n",
                "For now, lets see how the model performs without balancing, and then compare the results with a balanced set later."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(284807, 30)\n",
                        "(284807,)\n"
                    ]
                }
            ],
            "source": [
                "# dividing the X and the Y from the dataset\n",
                "X = data.drop(['Class'], axis = 1)\n",
                "Y = data[\"Class\"]\n",
                "\n",
                "print(X.shape)\n",
                "print(Y.shape)\n",
                "\n",
                "# getting just the values for the sake of processing \n",
                "# (its a numpy array with no columns)\n",
                "xData = X.values\n",
                "yData = Y.values"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [],
            "source": [
                "# splitting the data into training and testing set\n",
                "from sklearn.model_selection import train_test_split\n",
                "# Split the data into training and testing sets\n",
                "xTrain, xTest, yTrain, yTest = train_test_split(\n",
                "        xData, yData, test_size = 0.2, random_state = 42)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Choosing an ML Model for our usecase: Random Forest Classification\n",
                "The Random Forest algorithm is a powerful tool for detecting credit card fraud due to its inherent characteristics. It is an ensemble learning method that operates by constructing multiple decision trees and outputting the majority vote of individual trees. \n",
                "\n",
                "The model is less prone to overfitting due to the randomness and diversity among the individual trees. Moreover, the algorithm can handle a large amount of data with numerous variables and manage missing values, making it suitable for complex datasets such as credit card transactions. \n",
                "\n",
                "Its ability to estimate the importance of features can be beneficial in identifying significant indicators of fraud. Furthermore, the random forest algorithm works well with imbalanced datasets, which is often the case with fraud detection, where the number of legitimate transactions significantly outweighs fraudulent ones. Therefore, it's an effective technique for such tasks.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Building the Random Forest Classifier (RANDOM FOREST)\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "# random forest model creation\n",
                "rfc = RandomForestClassifier()\n",
                "rfc.fit(xTrain, yTrain)\n",
                "# predictions\n",
                "yPred = rfc.predict(xTest)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "The model used is Random Forest classifier\n",
                        "The accuracy is 0.9995786664794073\n",
                        "The precision is 0.9743589743589743\n",
                        "The recall is 0.7755102040816326\n",
                        "The F1-Score is 0.8636363636363635\n",
                        "The Matthews correlation coefficient is 0.8690748763736589\n",
                        "The AUC is 0.8877375162220206\n"
                    ]
                }
            ],
            "source": [
                "# Evaluating the classifier\n",
                "# printing every score of the classifier\n",
                "# scoring in anything\n",
                "from sklearn.metrics import classification_report, accuracy_score \n",
                "from sklearn.metrics import precision_score, recall_score\n",
                "from sklearn.metrics import f1_score, matthews_corrcoef\n",
                "from sklearn.metrics import confusion_matrix\n",
                "from sklearn.metrics import roc_auc_score\n",
                "  \n",
                "n_outliers = len(fraud)\n",
                "n_errors = (yPred != yTest).sum()\n",
                "print(\"The model used is Random Forest classifier\")\n",
                "  \n",
                "acc = accuracy_score(yTest, yPred)\n",
                "print(\"The accuracy is {}\".format(acc))\n",
                "  \n",
                "prec = precision_score(yTest, yPred)\n",
                "print(\"The precision is {}\".format(prec))\n",
                "  \n",
                "rec = recall_score(yTest, yPred)\n",
                "print(\"The recall is {}\".format(rec))\n",
                "  \n",
                "f1 = f1_score(yTest, yPred)\n",
                "print(\"The F1-Score is {}\".format(f1))\n",
                "  \n",
                "MCC = matthews_corrcoef(yTest, yPred)\n",
                "print(\"The Matthews correlation coefficient is {}\".format(MCC))\n",
                "\n",
                "auc = roc_auc_score(yTest, yPred)\n",
                "print(\"The AUC is {}\".format(auc))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Results\n",
                "\n",
                "1. **Accuracy (0.9995786664794073)**: This metric represents the proportion of total predictions that were correct. In this case, the model has a very high accuracy, indicating that it correctly identified fraudulent and non-fraudulent transactions in about 99.96% of cases. However, in imbalanced datasets, accuracy can be misleading because it does not differentiate between the classes.\n",
                "\n",
                "2. **Precision (0.9743589743589743)**: Precision is the proportion of positive identifications (in this case, predicted fraudulent transactions) that were actually correct. A high precision means a low false positive rate. With a precision of about 97.43%, the model is very good at not labelling a transaction as fraudulent when it is not.\n",
                "\n",
                "3. **Recall (0.7755102040816326)**: Recall (or sensitivity) is the proportion of actual positives that were identified correctly. It is particularly important in situations like fraud detection, where it is crucial to capture as many positives as possible. Your model's recall is about 77.55%, which suggests there is room for improvement. This implies that the model is missing about 22.45% of fraudulent transactions.\n",
                "\n",
                "3. **F1-Score (0.8636363636363635)**: The F1-score is the harmonic mean of precision and recall. It tries to find the balance between precision and recall. In the case, the F1-Score is 0.86 which is pretty good, indicating a decent balance between precision and recall.\n",
                "\n",
                "4. **Matthews correlation coefficient (0.8690748763736589)**: This is a measure of the quality of binary classifications. It takes into account true and false positives and negatives and is generally regarded as a balanced measure which can be used even if the classes are of very different sizes. A coefficient of +1 represents a perfect prediction, 0 an average random prediction and -1 an inverse prediction. In the case, a MCC of 0.87 is a very good value.\n",
                "\n",
                "5. **AUC (0.8877375162220206)**: The Area Under the Curve (AUC) is a performance measurement for classification problems at various thresholds settings. ROC is a probability curve and AUC represents the degree or measure of separability. It tells how much the model is capable of distinguishing between classes. An AUC of 0.88 indicates a very good performance of the model in terms of its ability to distinguish between fraudulent and non-fraudulent transactions.\n",
                "\n",
                "While the model has high accuracy and precision, its relatively lower recall suggests that it's not capturing all the fraudulent transactions effectively. Since it's critical in a fraud detection task to correctly identify as many fraudulent transactions as possible (even at the risk of some false positives), we may need to adjust the model or rebalance the dataset to improve the recall rate."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## rebalancing the data\n",
                "\n",
                "Here are several techniques we can use to balance our data:\n",
                "\n",
                "1. Undersampling: In this method, you randomly remove some of the samples from the majority class to balance the ratio between the majority and minority class. The disadvantage is that you lose potentially useful data.\n",
                "\n",
                "2. Oversampling: Here, you increase the number of samples in the minority class by randomly replicating them. The disadvantage is that by duplicating the data, the model may overfit the data.\n",
                "\n",
                "3. SMOTE (Synthetic Minority Over-Sampling Technique): This is a popular algorithm to create synthetic samples of the minority class. It works by selecting examples that are close in the feature space, drawing a line between the examples in the feature space and drawing a new sample at a point along that line."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Original dataset shape: Counter({0: 284315, 1: 492})\n",
                        "Resampled (undersampling) dataset shape: Counter({0: 492, 1: 492})\n"
                    ]
                }
            ],
            "source": [
                "from imblearn.under_sampling import RandomUnderSampler\n",
                "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
                "from collections import Counter\n",
                "\n",
                "print('Original dataset shape:', Counter(Y))\n",
                "\n",
                "# Random Under-sampling\n",
                "rus = RandomUnderSampler(random_state=42)\n",
                "X_rus, Y_rus = rus.fit_resample(X, Y)\n",
                "print('Resampled (undersampling) dataset shape:', Counter(Y_rus))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "metadata": {},
            "outputs": [],
            "source": [
                "# let's see how the undersampled data performs with Random Forest classifier\n",
                "\n",
                "# getting just the values for the sake of processing \n",
                "# (its a numpy array with no columns)\n",
                "xData = X_rus.values\n",
                "yData = Y_rus.values\n",
                "\n",
                "# splitting the data into training and testing set\n",
                "from sklearn.model_selection import train_test_split\n",
                "# Split the data into training and testing sets\n",
                "xTrain, xTest, yTrain, yTest = train_test_split(\n",
                "        xData, yData, test_size = 0.2, random_state = 42)\n",
                "\n",
                "# Building the Random Forest Classifier (RANDOM FOREST)\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "# random forest model creation\n",
                "rfc = RandomForestClassifier()\n",
                "rfc.fit(xTrain, yTrain)\n",
                "# predictions\n",
                "yPred = rfc.predict(xTest)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "The model used is Random Forest classifier\n",
                        "The accuracy is 0.9238578680203046\n",
                        "The precision is 0.9560439560439561\n",
                        "The recall is 0.8877551020408163\n",
                        "The F1-Score is 0.9206349206349207\n",
                        "The Matthews correlation coefficient is 0.849807156821831\n",
                        "The AUC is 0.9236755308183879\n"
                    ]
                }
            ],
            "source": [
                "# Evaluating the classifier\n",
                "# printing every score of the classifier\n",
                "# scoring in anything\n",
                "from sklearn.metrics import classification_report, accuracy_score \n",
                "from sklearn.metrics import precision_score, recall_score\n",
                "from sklearn.metrics import f1_score, matthews_corrcoef\n",
                "from sklearn.metrics import confusion_matrix\n",
                "from sklearn.metrics import roc_auc_score\n",
                "  \n",
                "n_outliers = len(fraud)\n",
                "n_errors = (yPred != yTest).sum()\n",
                "print(\"The model used is Random Forest classifier\")\n",
                "  \n",
                "acc = accuracy_score(yTest, yPred)\n",
                "print(\"The accuracy is {}\".format(acc))\n",
                "  \n",
                "prec = precision_score(yTest, yPred)\n",
                "print(\"The precision is {}\".format(prec))\n",
                "  \n",
                "rec = recall_score(yTest, yPred)\n",
                "print(\"The recall is {}\".format(rec))\n",
                "  \n",
                "f1 = f1_score(yTest, yPred)\n",
                "print(\"The F1-Score is {}\".format(f1))\n",
                "  \n",
                "MCC = matthews_corrcoef(yTest, yPred)\n",
                "print(\"The Matthews correlation coefficient is {}\".format(MCC))\n",
                "\n",
                "auc = roc_auc_score(yTest, yPred)\n",
                "print(\"The AUC is {}\".format(auc))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Results\n",
                "\n",
                "1. **Accuracy (0.9238578680203046):** The accuracy has decreased from 0.9996 to 0.9239, which means the model is now making more misclassifications overall. However, given the imbalance in the dataset, this is not necessarily a bad thing if the model has become better at detecting fraud.\n",
                "\n",
                "2. **Precision (0.9560439560439561):** Precision has decreased slightly from 0.9744 to 0.9560, suggesting a slight increase in the number of false positives (transactions that were non-fraudulent but were identified as fraudulent). In the context of fraud detection, this might be acceptable if the model can detect more true fraudulent cases.\n",
                "\n",
                "3. **Recall (0.8877551020408163):** The recall has improved from 0.7755 to 0.8878. This means the model is now better at detecting fraudulent transactions, which is critical in this context.\n",
                "\n",
                "4. **F1-Score (0.9206349206349207):** The F1-Score has increased from 0.8636 to 0.9206, suggesting that the balance between precision and recall has improved. This is a positive development, as both precision and recall are important in a fraud detection context.\n",
                "\n",
                "5. **Matthews correlation coefficient (0.849807156821831):** This metric has decreased slightly from 0.8691 to 0.8498, which indicates a slight decrease in the overall quality of binary classifications. However, it remains high, indicating a generally good quality of predictions.\n",
                "\n",
                "6. **AUC (0.9236755308183879):** The AUC has increased from 0.8877 to 0.9237, suggesting that the model's ability to distinguish between fraudulent and non-fraudulent transactions has improved.\n",
                "\n",
                "Overall, while accuracy and precision have dropped slightly after applying undersampling, the model has improved in terms of recall, F1-Score, and AUC. This suggests that despite making more overall mistakes, the model is better at identifying fraudulent transactions, which is usually the priority in fraud detection. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 36,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Original dataset shape: Counter({0: 284315, 1: 492})\n",
                        "Resampled (oversampling) dataset shape: Counter({0: 284315, 1: 284315})\n"
                    ]
                }
            ],
            "source": [
                "from imblearn.under_sampling import RandomUnderSampler\n",
                "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
                "from collections import Counter\n",
                "\n",
                "print('Original dataset shape:', Counter(Y))\n",
                "\n",
                "# Random Over-sampling\n",
                "ros = RandomOverSampler(random_state=42)\n",
                "X_ros, Y_ros = ros.fit_resample(X, Y)\n",
                "print('Resampled (oversampling) dataset shape:', Counter(Y_ros))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "metadata": {},
            "outputs": [],
            "source": [
                "# let's see how the undersampled data performs with Random Forest classifier\n",
                "\n",
                "# getting just the values for the sake of processing \n",
                "# (its a numpy array with no columns)\n",
                "xData = X_ros.values\n",
                "yData = Y_ros.values\n",
                "\n",
                "# splitting the data into training and testing set\n",
                "from sklearn.model_selection import train_test_split\n",
                "# Split the data into training and testing sets\n",
                "xTrain, xTest, yTrain, yTest = train_test_split(\n",
                "        xData, yData, test_size = 0.2, random_state = 42)\n",
                "\n",
                "# Building the Random Forest Classifier (RANDOM FOREST)\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "# random forest model creation\n",
                "rfc = RandomForestClassifier()\n",
                "rfc.fit(xTrain, yTrain)\n",
                "# predictions\n",
                "yPred = rfc.predict(xTest)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 38,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "The model used is Random Forest classifier\n",
                        "The accuracy is 0.9999560346798445\n",
                        "The precision is 0.9999122514522385\n",
                        "The recall is 1.0\n",
                        "The F1-Score is 0.9999561238010829\n",
                        "The Matthews correlation coefficient is 0.9999120728626671\n",
                        "The AUC is 0.9999559471365639\n"
                    ]
                }
            ],
            "source": [
                "# Evaluating the classifier\n",
                "# printing every score of the classifier\n",
                "# scoring in anything\n",
                "from sklearn.metrics import classification_report, accuracy_score \n",
                "from sklearn.metrics import precision_score, recall_score\n",
                "from sklearn.metrics import f1_score, matthews_corrcoef\n",
                "from sklearn.metrics import confusion_matrix\n",
                "from sklearn.metrics import roc_auc_score\n",
                "  \n",
                "n_outliers = len(fraud)\n",
                "n_errors = (yPred != yTest).sum()\n",
                "print(\"The model used is Random Forest classifier\")\n",
                "  \n",
                "acc = accuracy_score(yTest, yPred)\n",
                "print(\"The accuracy is {}\".format(acc))\n",
                "  \n",
                "prec = precision_score(yTest, yPred)\n",
                "print(\"The precision is {}\".format(prec))\n",
                "  \n",
                "rec = recall_score(yTest, yPred)\n",
                "print(\"The recall is {}\".format(rec))\n",
                "  \n",
                "f1 = f1_score(yTest, yPred)\n",
                "print(\"The F1-Score is {}\".format(f1))\n",
                "  \n",
                "MCC = matthews_corrcoef(yTest, yPred)\n",
                "print(\"The Matthews correlation coefficient is {}\".format(MCC))\n",
                "\n",
                "auc = roc_auc_score(yTest, yPred)\n",
                "print(\"The AUC is {}\".format(auc))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Results\n",
                "\n",
                "1. **Accuracy (0.9999560346798445):** The accuracy has slightly increased from the original model (0.9995786664794073 to 0.9999560346798445). This means the model is correctly identifying fraudulent and non-fraudulent transactions almost all the time.\n",
                "\n",
                "2. **Precision (0.9999122514522385):** Precision has slightly increased compared to the original model (from 0.9743589743589743 to 0.9999122514522385), indicating that almost all transactions identified as fraudulent are indeed fraudulent. There are very few false positives.\n",
                "\n",
                "3. **Recall (1.0):** The recall has significantly improved from 0.7755102040816326 to 1.0, suggesting that the model is now able to identify all fraudulent transactions correctly. This is an excellent result because in the context of fraud detection, it is crucial to identify as many fraudulent cases as possible.\n",
                "\n",
                "4. **F1-Score (0.9999561238010829):** The F1-Score, which balances precision and recall, has significantly improved (from 0.8636363636363635 to 0.9999561238010829). This suggests that the model has improved in terms of both precision and recall.\n",
                "\n",
                "5. **Matthews correlation coefficient (0.9999120728626671):** The Matthews correlation coefficient has improved from 0.8690748763736589 to 0.9999120728626671, indicating a significant improvement in the quality of binary classifications.\n",
                "\n",
                "6. **AUC (0.9999559471365639):** The AUC score has increased from 0.8877375162220206 to 0.9999559471365639, indicating that the model's ability to distinguish between fraudulent and non-fraudulent transactions has improved drastically.\n",
                "\n",
                "Overall, the oversampling has significantly improved the model's performance across all metrics, especially in terms of recall, which is crucial in fraud detection. However, it's worth noting that these results may be too good to be true and might indicate overfitting due to the replication of data in oversampling. It's crucial to test the model with a separate, unseen dataset to ensure it generalizes well. It's also important to remember that oversampling doesn't add any new information to the model, which might limit its ability to detect different or evolving types of fraud."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.9.13 64-bit",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.13"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
